{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "\n",
    "artist_index_url = \"https://bandcamp.com/artist_index\" #Set the url for all artists\n",
    "html = urllib.request.urlopen(artist_index_url) # Open the page\n",
    "soup = BeautifulSoup(html,'html.parser') #Use beautifulSoup to access html  \n",
    "\n",
    "# Init variables to be stored in CSV file\n",
    "ARTIST_ = []\n",
    "ALBUM_ = []\n",
    "SONG_ = []\n",
    "LENGTH_ = []\n",
    "LOCATION_ = []\n",
    "related_tags = []\n",
    "\n",
    "\n",
    "# Get the maximum page value to use as the end point (This is probably a waste of a function)\n",
    "def get_max_pages(soup):\n",
    "    n_pages = []\n",
    "    for page in soup.find_all(\"a\",{\"rel\":\"nofollow\"}):\n",
    "        n_pages.append(int(page.text))\n",
    "    max_pages = max(n_pages)\n",
    "    return max_pages\n",
    "\n",
    "max_pages = get_max_pages(soup)\n",
    "print(max_pages)\n",
    "\n",
    "######\n",
    "###################################################\n",
    "def get_artist_info(artist_soup):\n",
    "    \n",
    "    # Get Artist Name\n",
    "    artist_name = artist_soup.find(\"span\",{\"itemprop\":\"byArtist\"}).text\n",
    "    artist_name.replace(\"\\\\n\",\" \")\n",
    "            \n",
    "    # Get Album Name\n",
    "    album_name = artist_soup.find(\"h2\",{\"class\":\"trackTitle\"}).text\n",
    "    album_name.replace(\"\\r\\n\",\" \")\n",
    "        \n",
    "    # Get Artist Location\n",
    "    artist_loc = artist_soup.find(\"span\",{\"class\":\"location secondaryText\"}).text\n",
    "    print(artist_loc)\n",
    "    \n",
    "    # Get the date\n",
    "    date = artist_soup.find(\"meta\",{\"itemprop\":\"datePublished\"})[\"content\"]\n",
    "        \n",
    "    # Get Album Tags\n",
    "    for tags in artist_soup.find_all(\"a\",{\"class\":\"tag\"}): \n",
    "        TAGS_.append(tags.text)\n",
    "            \n",
    "    # Get Songs\n",
    "    for song in artist_soup.find_all(\"span\", {\"itemprop\":\"name\"}):\n",
    "        SONG_.append(song.text)       \n",
    "      \n",
    "    output = [artist_name,album_name,artist_loc,date,TAGS_,SONG_]    \n",
    "    return output\n",
    "################################################################\n",
    "\n",
    "\n",
    "# Create/Open the CSV File you will be writing too!\n",
    "with open('Bandcamp_MASTER.csv','w') as csvfile:\n",
    "    fieldnames = ['Artist','Album','Song','Length','Location','Tags']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fieldnames, lineterminator = '\\n')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    page_url = \"?page=1\" # Initialize the 1st page as default\n",
    "    \n",
    "    # This will loop for every page available (1-->max_pages)\n",
    "    for page in range(1, max_pages):\n",
    "        \n",
    "        # Get the url for the page number and open it with BeautifulSoup\n",
    "        page_url = page_url.replace(page_url[len(page_url) - 1], str(page)) # replace the previous page number    \n",
    "        page_html = artist_index_url + page_url # create the new link for the next page to scan\n",
    "        page_html = urllib.request.urlopen(page_html) # open the next page\n",
    "        soup = BeautifulSoup(page_html,'html.parser') # Pull the data from the next page \n",
    "        \n",
    "       # Get the artists on that page and append it to the complete artist list\n",
    "\n",
    "        artist_class = soup.find('ul', {\"class\":\"item_list\"}) # Finds the html section that includes all artist links\n",
    "        for a_link in artist_class.find_all('a', href = True):\n",
    "            print(a_link[\"href\"]) # print the artist's url\n",
    "            artist_url = a_link[\"href\"] # create variable for artist's url\n",
    "            artist_html = urllib.request.urlopen(artist_url) # open the artist's url\n",
    "            artist_soup = BeautifulSoup(artist_html,'html.parser') # Pull the data from artist's url     \n",
    "            \n",
    "            try:                                    \n",
    "                album_soup = artist_soup.find('ol', {\"data-edit-callback\" : \"/music_reorder\"})\n",
    "                for l in album_soup.find_all('a',href = True):\n",
    "                    # checks if it's just a single song or an album\n",
    "                    if \"track\" in l[\"href\"]: # It's just a song\n",
    "                        track_url = artist_url + l[\"href\"]\n",
    "                        track_html = urllib.request.urlopen(track_url)\n",
    "                        track_soup = BeautifulSoup(track_html,'html.parser')\n",
    "                        song_title = track_soup.find(\"h2\",{\"class\":\"trackTitle\"}).text\n",
    "                        song_duraion = track_soup.find(\"span\",{\"class\":\"time_total\"}).text #WHY WON't THIS WORK\n",
    "                        album_title = \"N/A\"\n",
    "                        location = track_soup.find(\"span\",{\"class\":\"location secondaryText\"}).text\n",
    "                        date = track_soup.find(\"meta\",{\"itemprop\":\"datePublished\"})\n",
    "                        print(date[\"content\"])\n",
    "                        for tags in track_soup.find_all(\"a\",{\"class\":\"tag\"}): \n",
    "                            related_tags.append(tags.text)\n",
    "                        \n",
    "                    elif \"album\" in l[\"href\"]: # It's an album!     \n",
    "                        print(\"hey\")\n",
    "                    else:\n",
    "                        print(\"OH1\")                    \n",
    "                             \n",
    "            except: \n",
    "                print(\"OH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
