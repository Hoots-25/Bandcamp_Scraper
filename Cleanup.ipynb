{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from os import chdir\n",
    "from glob import glob\n",
    "\n",
    "# Produce a single CSV after combining all files\n",
    "def produceOneCSV(list_of_files, file_out):\n",
    "   # Consolidate all CSV files into one object\n",
    "   result_obj = pd.concat([pd.read_csv(file) for file in list_of_files])\n",
    "   # Convert the above object into a csv file and export\n",
    "   result_obj.to_csv(file_out, index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# Move to the path that holds our CSV files\n",
    "csv_file_path = r\"C:\\Users\\domen\\Desktop\\Data Scraping\\v2\\CSVs\"\n",
    "list_of_files = [f for f in os.listdir(csv_file_path) if f.endswith('.csv')]\n",
    "os. chdir(r\"C:\\Users\\domen\\Desktop\\Data Scraping\\v2\\CSVs\")\n",
    "        \n",
    "print(list_of_files)\n",
    "file_out = \"ConsolidateOutput.csv\"\n",
    "produceOneCSV(list_of_files, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\domen\\Desktop\\Data Scraping\\v2\\CSVs\\cleanup8.csv\")\n",
    "start_time = datetime.datetime.now()\n",
    "print(start_time)\n",
    "\n",
    "data.drop_duplicates(keep = False, inplace = True)\n",
    "num_row = len(data.Length)\n",
    "print(\"Num Rows: \", num_row)\n",
    "count = 0\n",
    "\n",
    "for i in range(0,num_row):\n",
    "    try:\n",
    "        \n",
    "        data.Length[i] = data.Length[i].replace(\"\\r\\n        \\r\\n            \",\"\")\n",
    "        data.Length[i] = data.Length[i].replace(\"\\r\\n        \\r\\n        \",\"\")\n",
    "        data.Length[i] = data.Length[i].rstrip()\n",
    "        data.Length[i] = data.Length[i].lstrip()\n",
    "        \n",
    "        data.Song[i] = data.Song[i].replace(\"            \",\"\")\n",
    "        data.Song[i] = data.Song[i].replace(\"                    \",\"\")    \n",
    "        data.Album[i] = data.Album[i].replace(\"            \",\"\")\n",
    "        data.Album[i] = data.Album[i].replace(\"                    \",\"\")\n",
    "        \n",
    "        if data.Length[i] == \"N\":\n",
    "            data.Length[i] = data.Length[i].replace(\"N\",\"N/A\")\n",
    "        elif data.Length[i] == \"\":\n",
    "            data.Length[i] = data.Length[i].replace(\"\",\"N/A\")\n",
    "        if np.isnan(data.Length[i]):\n",
    "            data.Length[i] = \"N/A\"\n",
    "        if data.Song[i][0:2] == \"['\":\n",
    "            data.Song[i] = data.Song[i][2:-2]  \n",
    "    except:\n",
    "        count += 1        \n",
    "        print(\"count: \", count)\n",
    "        continue\n",
    "        \n",
    "# Convert the above object into a csv file and export\n",
    "data.to_csv(r\"C:\\Users\\domen\\Desktop\\Data Scraping\\v2\\CSVs\\cleanup9.csv\", index = False, encoding = \"utf-8\")\n",
    "end_time = datetime.datetime.now()\n",
    "print(end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
